{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import PIL\n",
    "import glob\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D,BatchNormalization,Activation,GRU\n",
    "from tensorflow.keras.applications import EfficientNetB7, VGG16 \n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling3D, Conv3D,Conv1D, MaxPooling1D,\n",
    "    MaxPooling2D) \n",
    "from collections import deque\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_dir = './toanalyze'\n",
    "\n",
    "data_dir = pathlib.Path(_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "batch_size = 2\n",
    "img_height = 274\n",
    "img_width = 274\n",
    "n_class=4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "train_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "    color_mode=\"rgb\",\n",
    "    label_mode='categorical',\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "validation_generator = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "    label_mode='categorical',\n",
    "    color_mode=\"rgb\",\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_generator.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        validation_split=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        subset='training',\n",
    "        target_size=(img_height,img_width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        subset='validation',\n",
    "        target_size=(img_height,img_width),\n",
    "        batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "train_samples = 174     #610 \n",
    "validation_samples = 42     #195\n",
    "n_channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs, labels= training_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(img_height,img_width,n_channel)\n",
    "\n",
    "def build_convnet_2D():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())q\n",
    "    model.add(Dense(32))\n",
    "    \n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_convnet_2_2D():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    model.add(Conv2D(256, (2,2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    " \n",
    "def build_cnn_lstm_2D():\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(8, return_sequences=True, dropout=0.5))\n",
    "    # model.add(Dropout(0.2)) #added\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    " \n",
    "def cv2d():    \n",
    "    model = Sequential()\n",
    "        # 1st layer group\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu',\n",
    "                          name='conv1',\n",
    "                         padding='same',\n",
    "                         input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(1, 1),\n",
    "                               padding='same', name='pool1'))\n",
    "        # 2nd layer group\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu',\n",
    "                         padding='same', name='conv2',\n",
    "                         ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1),\n",
    "                               padding='same', name='pool2'))\n",
    "        # 3rd layer group\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu',\n",
    "                         padding='same', name='conv3a',\n",
    "                         ))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu',\n",
    "                         padding='same', name='conv3b',\n",
    "                         ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1),\n",
    "                               padding='same', name='pool3'))\n",
    "       \n",
    "\n",
    "        # FC layers group\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_gru_conv2D_1():\n",
    "    cmodel = Sequential()\n",
    "\n",
    "    cmodel.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    cmodel.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    cmodel.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
    "    cmodel.add(MaxPooling1D(pool_size=2, strides=1))\n",
    "    \n",
    "    cmodel.add(Flatten())\n",
    "    cmodel.add(Dense(32))\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(TimeDistributed(cmodel))\n",
    "    model.add(TimeDistributed(cmodel, input_shape=(input_shape)))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(16))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gru_conv2D():\n",
    "    model = Sequential()# input, with 64 convolutions for 5 images\n",
    "    # that have (224, 224, 3) shape\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            Conv2D(64, (3,3), \n",
    "                padding='same', strides=(2,2), activation='relu'),\n",
    "            \n",
    "            input_shape = input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed( \n",
    "            Conv2D(64, (3,3), \n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            MaxPooling2D((2,2), strides=(2,2))\n",
    "        )\n",
    "    )# Second conv, 128\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            Conv2D(128, (3,3),\n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed( \n",
    "            Conv2D(128, (3,3),\n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            MaxPooling2D((2,2), strides=(2,2))\n",
    "        )\n",
    "    )## and so on with 512, 1024... \n",
    "    ## ...# then we can use Flatten to reduce dimension to 1\n",
    "    model.add(Flatten())## and then... merge the entire outputs to\n",
    "    ## be able to use Dense(), and make predictions...\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def simple_gru_conv2d():\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape)))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(GRU(8, return_sequences=True, dropout=0.5))\n",
    "    # model.add(Dropout(0.2)) #added\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def hybrid():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(32, 4, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(16, 8, activation=\"relu\", padding='same'))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(16, 8, activation=\"relu\", padding='same'))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(n_class, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_convnet_2D()\n",
    "# model = build_convnet_2_2D()\n",
    "# model = build_cnn_lstm_2D()\n",
    "# model = build_gru_conv2D_1()\n",
    "# model = cv2d()\n",
    "# model = build_gru_conv2D()\n",
    "# model = simple_gru_conv2d()\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_convnet_1()\n",
    "# model = build_convnet_2()\n",
    "# model = build_gru_conv() \n",
    "# model = cv3d()\n",
    "# model = c3d()\n",
    "# model = simple_gru_conv()\n",
    "# model = build_cnn_lstm()\n",
    "# model = hybrid()\n",
    "# model = build_cnn_lstm_2D()\n",
    "model = build_gru_conv2D_1()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_convnet_2D()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "h2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB7(include_top=False, input_shape=input_shape)\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(n_class, activation='softmax')(class1)\n",
    "# define new 4\n",
    "model = tf.keras.Model(inputs=model.inputs, outputs=output)\n",
    "# summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"VGG.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB7(include_top=False, input_shape=input_shape)\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(n_class, activation='softmax')(class1)\n",
    "# define new 4\n",
    "model = tf.keras.Model(inputs=model.inputs, outputs=output)\n",
    "# summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = h.history['accuracy']\n",
    "val_acc = h.history['val_accuracy']\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "  if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print('Normalized confusion matrix')\n",
    "  else:\n",
    "    print('Confusion matrix, without normalization')\n",
    "\n",
    "  print(cm)\n",
    "\n",
    "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks= np.arange(len(classes))\n",
    "  plt.xticks(tick_marks, classes, rotation=45)\n",
    "  plt.yticks(tick_marks, classes)\n",
    "\n",
    "  fmt = '.2f' if normalize else 'd'\n",
    "  thresh = cm.max()/2.\n",
    "\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j,i, format(cm[i,j], fmt), horizontalalignment='center', color='white' if cm[i,j]> thresh else 'black')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=validation_generator.n//validation_generator.batch_size\n",
    "pred = model.predict(validation_generator,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "trueclasses = validation_generator.classes\n",
    "labels = (validation_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "y_pred = [labels[k] for k in predicted_class_indices]\n",
    "y_true = [labels[k] for k in trueclasses]\n",
    "f1_score(y_true, y_pred, average='weighted') #None\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, list(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, list(range(4)),normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio \n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r'.\\input-gray\\val\\Alanya\\2019-12-23\\ANT191223070003.PPINW4L.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i0 = imageio.imread(dir)\n",
    "plt.imshow(i0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = ['west','east','center','Sparse']\n",
    "\n",
    "class_info2 = ['Aksu','Alanya','Antalya','Finike','Gazipasa','Kas','Kemer','Kumluca','Manavgat','Serik','Sparse']\n",
    "\n",
    "from tweaked_ImageGenerator_v2 import ImageDataGenerator\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator=datagen.flow_from_directory(\n",
    "            'newinput_charts/train', \n",
    "            target_size=(112,112), \n",
    "            class_mode='categorical',\n",
    "            classes=class_info,\n",
    "            color_mode='rgb', \n",
    "            batch_size=8, frames_per_step=5, shuffle=True)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "            directory='newinput_charts/val',\n",
    "            color_mode='rgb',\n",
    "            target_size=(112,112),\n",
    "            classes=class_info,\n",
    "            frames_per_step=5, \n",
    "            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_conv2d():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, (3,3, 3), input_shape=(13,224,224,1), activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# model = build_simple_conv2d()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# epochs = 30\n",
    "# train_samples = 1853  #1485\n",
    "# validation_samples = 338 #368\n",
    "# batch_size=16\n",
    "# x = model.fit(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=train_samples // batch_size,\n",
    "#         epochs=epochs,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (5,112,112,3)\n",
    "n_class=5\n",
    "def build_convnet_2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, (3,3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "    \n",
    "    model.add(Conv3D(64, (3,3,3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "    model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "    model.add(Conv3D(128, (3,3,3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "    model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "    model.add(Conv3D(256, (2,2,2), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    " \n",
    "\n",
    "def build_cnn_lstm():\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn_model.add(Flatten())\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(cnn_model))\n",
    "    model.add(LSTM(8, return_sequences=True, dropout=0.5))\n",
    "    # model.add(Dropout(0.2)) #added\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def cv3d():    \n",
    "    model = Sequential()\n",
    "        # 1st layer group\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu',\n",
    "                          name='conv1',\n",
    "                         padding='same',\n",
    "                         input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                               padding='same', name='pool1'))\n",
    "        # 2nd layer group\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv2',\n",
    "                         ))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='same', name='pool2'))\n",
    "        # 3rd layer group\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv3a',\n",
    "                         ))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv3b',\n",
    "                         ))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='same', name='pool3'))\n",
    "        # 4th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv4a',\n",
    "                         ))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv4b',\n",
    "                         ))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='same', name='pool4'))\n",
    "\n",
    "        # 5th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv5a',\n",
    "                          ))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                         padding='same', name='conv5b',\n",
    "                          ))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='same', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "\n",
    "        # FC layers group\n",
    "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def c3d():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(32, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "     \n",
    "\n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #softmax layer\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def build_gru_conv2():\n",
    "    cmodel = Sequential()\n",
    "    cmodel.add(Conv2D(128, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    cmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    cmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    cmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "    \n",
    "    cmodel.add(Flatten())\n",
    "    cmodel.add(Dense(32))\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(TimeDistributed(cmodel))\n",
    "    model.add(TimeDistributed(cmodel, input_shape=input_shape))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(16))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_gru_conv():\n",
    "    model = Sequential()# input, with 64 convolutions for 5 images\n",
    "    # that have (224, 224, 3) shape\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            Conv2D(64, (3,3), \n",
    "                padding='same', strides=(2,2), activation='relu'),\n",
    "            \n",
    "            input_shape = input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed( \n",
    "            Conv2D(64, (3,3), \n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            MaxPooling2D((2,2), strides=(2,2))\n",
    "        )\n",
    "    )# Second conv, 128\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            Conv2D(128, (3,3),\n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed( \n",
    "            Conv2D(128, (3,3),\n",
    "                padding='same', strides=(2,2), activation='relu')\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed(\n",
    "            MaxPooling2D((2,2), strides=(2,2))\n",
    "        )\n",
    "    )## and so on with 512, 1024... \n",
    "    ## ...# then we can use Flatten to reduce dimension to 1\n",
    "    model.add(Flatten())## and then... merge the entire outputs to\n",
    "    ## be able to use Dense(), and make predictions...\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \n",
    "       \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks= np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max()/2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, format(cm[i,j], fmt), horizontalalignment='center', color='white' if cm[i,j]> thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf24",
   "language": "python",
   "name": "tf24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
